{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":46346,"sourceType":"datasetVersion","datasetId":34662}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install tensorflow opencv-python-headless matplotlib\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:36:47.510953Z","iopub.execute_input":"2024-09-02T16:36:47.511617Z","iopub.status.idle":"2024-09-02T16:37:01.729364Z","shell.execute_reply.started":"2024-09-02T16:36:47.511575Z","shell.execute_reply":"2024-09-02T16:37:01.728136Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (4.10.0.84)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom PIL import Image\nimport numpy as np\nimport os\nfrom xml.etree import ElementTree as et\nfrom sklearn.model_selection import train_test_split\n\n# Define your root directories\ntrain_root = '/kaggle/input/fruit-images-for-object-detection/train_zip/train'\nval_root = '/kaggle/input/fruit-images-for-object-detection/test_zip/test'\n\n# Define your labels\nlabels = ['background', 'orange', 'apple', 'banana']\nlabel2targets = {l: t for t, l in enumerate(labels)}\nnum_classes = len(labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:52:29.371291Z","iopub.execute_input":"2024-09-02T16:52:29.372037Z","iopub.status.idle":"2024-09-02T16:52:33.241133Z","shell.execute_reply.started":"2024-09-02T16:52:29.371996Z","shell.execute_reply":"2024-09-02T16:52:33.240049Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def preprocess_img(img_path):\n    img = Image.open(img_path).convert('RGB')\n    img = img.resize((224, 224))  # Resize the image to a fixed size\n    img = np.array(img)\n    return img\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:52:33.243155Z","iopub.execute_input":"2024-09-02T16:52:33.243767Z","iopub.status.idle":"2024-09-02T16:52:33.249446Z","shell.execute_reply.started":"2024-09-02T16:52:33.243726Z","shell.execute_reply":"2024-09-02T16:52:33.248447Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def load_dataset(root):\n    images = []\n    targets = []\n    xml_paths = sorted([os.path.join(root, file) for file in os.listdir(root) if file.endswith('.xml')])\n    for xml_path in xml_paths:\n        img_path = xml_path.replace('.xml', '.jpg')\n        img = preprocess_img(img_path)\n        tree = et.parse(xml_path)\n        root = tree.getroot()\n        for obj in root.findall('object'):\n            label = obj.find('name').text\n            label_id = label2targets.get(label, 0)  # Assign 0 (background) if label not found\n            box = obj.find('bndbox')\n            xmin = int(box.find('xmin').text)\n            ymin = int(box.find('ymin').text)\n            xmax = int(box.find('xmax').text)\n            ymax = int(box.find('ymax').text)\n            targets.append([xmin, ymin, xmax, ymax, label_id])  # Store targets as a list\n            images.append(img)\n    return np.array(images), np.array(targets)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:52:33.251504Z","iopub.execute_input":"2024-09-02T16:52:33.251809Z","iopub.status.idle":"2024-09-02T16:52:33.262563Z","shell.execute_reply.started":"2024-09-02T16:52:33.251777Z","shell.execute_reply":"2024-09-02T16:52:33.261766Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\nX_train, y_train = load_dataset(train_root)\nX_val, y_val = load_dataset(val_root)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:52:33.264722Z","iopub.execute_input":"2024-09-02T16:52:33.265011Z","iopub.status.idle":"2024-09-02T16:52:37.831726Z","shell.execute_reply.started":"2024-09-02T16:52:33.264980Z","shell.execute_reply":"2024-09-02T16:52:37.830695Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_model(num_classes):\n    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    for layer in base_model.layers:\n        layer.trainable = False\n    x = layers.GlobalAveragePooling2D()(base_model.output)\n    x = layers.Dense(256, activation='relu')(x)\n    outputs = layers.Dense(num_classes)(x)\n    model = keras.Model(inputs=base_model.input, outputs=outputs)\n    return model\n\n# Compile your model\nmodel = get_model(num_classes)\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:52:37.832871Z","iopub.execute_input":"2024-09-02T16:52:37.833185Z","iopub.status.idle":"2024-09-02T16:52:39.706438Z","shell.execute_reply.started":"2024-09-02T16:52:37.833153Z","shell.execute_reply":"2024-09-02T16:52:39.705441Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Train your model\nmodel.fit(X_train, y_train[:, -1], epochs=30, batch_size=32, validation_data=(X_val, y_val[:, -1]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:52:39.708063Z","iopub.execute_input":"2024-09-02T16:52:39.708475Z","iopub.status.idle":"2024-09-02T16:53:24.130336Z","shell.execute_reply.started":"2024-09-02T16:52:39.708431Z","shell.execute_reply":"2024-09-02T16:53:24.129350Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1725295966.491350     927 service.cc:145] XLA service 0x7d3e4c004660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1725295966.491742     927 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 3/15\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2934 - loss: 1.7266 ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1725295970.489083     927 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 694ms/step - accuracy: 0.5665 - loss: 1.0190 - val_accuracy: 0.8974 - val_loss: 0.3495\nEpoch 2/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8912 - loss: 0.3110 - val_accuracy: 0.8547 - val_loss: 0.4909\nEpoch 3/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9137 - loss: 0.3110 - val_accuracy: 0.8718 - val_loss: 0.5624\nEpoch 4/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8932 - loss: 0.2755 - val_accuracy: 0.8034 - val_loss: 0.8895\nEpoch 5/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8734 - loss: 0.3076 - val_accuracy: 0.9145 - val_loss: 0.3744\nEpoch 6/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9363 - loss: 0.1585 - val_accuracy: 0.8974 - val_loss: 0.3857\nEpoch 7/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8901 - loss: 0.2404 - val_accuracy: 0.9145 - val_loss: 0.3913\nEpoch 8/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9134 - loss: 0.2212 - val_accuracy: 0.8803 - val_loss: 0.3743\nEpoch 9/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9131 - loss: 0.2176 - val_accuracy: 0.9145 - val_loss: 0.3328\nEpoch 10/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9251 - loss: 0.1880 - val_accuracy: 0.9145 - val_loss: 0.3333\nEpoch 11/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9356 - loss: 0.1468 - val_accuracy: 0.9145 - val_loss: 0.3480\nEpoch 12/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9244 - loss: 0.1729 - val_accuracy: 0.8803 - val_loss: 0.3716\nEpoch 13/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9044 - loss: 0.2723 - val_accuracy: 0.8718 - val_loss: 0.4141\nEpoch 14/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9037 - loss: 0.2183 - val_accuracy: 0.9145 - val_loss: 0.3528\nEpoch 15/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9334 - loss: 0.1528 - val_accuracy: 0.8803 - val_loss: 0.3982\nEpoch 16/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9145 - loss: 0.1771 - val_accuracy: 0.9145 - val_loss: 0.3589\nEpoch 17/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9112 - loss: 0.1628 - val_accuracy: 0.9145 - val_loss: 0.3482\nEpoch 18/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8935 - loss: 0.1906 - val_accuracy: 0.8889 - val_loss: 0.4332\nEpoch 19/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9000 - loss: 0.2018 - val_accuracy: 0.8718 - val_loss: 0.4693\nEpoch 20/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8919 - loss: 0.2075 - val_accuracy: 0.8974 - val_loss: 0.4170\nEpoch 21/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9033 - loss: 0.2299 - val_accuracy: 0.9145 - val_loss: 0.3457\nEpoch 22/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8789 - loss: 0.2279 - val_accuracy: 0.9145 - val_loss: 0.3515\nEpoch 23/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8993 - loss: 0.2760 - val_accuracy: 0.8889 - val_loss: 0.4171\nEpoch 24/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9268 - loss: 0.1740 - val_accuracy: 0.8974 - val_loss: 0.3985\nEpoch 25/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8939 - loss: 0.2210 - val_accuracy: 0.8889 - val_loss: 0.4010\nEpoch 26/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9149 - loss: 0.1923 - val_accuracy: 0.9145 - val_loss: 0.3319\nEpoch 27/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9358 - loss: 0.1430 - val_accuracy: 0.8718 - val_loss: 0.4058\nEpoch 28/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9196 - loss: 0.1700 - val_accuracy: 0.8974 - val_loss: 0.3720\nEpoch 29/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9333 - loss: 0.1837 - val_accuracy: 0.8632 - val_loss: 0.5020\nEpoch 30/30\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9045 - loss: 0.2255 - val_accuracy: 0.8803 - val_loss: 0.4021\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d3ec81f8040>"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate your model\nmodel.evaluate(X_val, y_val[:, -1])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:53:24.131689Z","iopub.execute_input":"2024-09-02T16:53:24.132429Z","iopub.status.idle":"2024-09-02T16:53:24.367356Z","shell.execute_reply.started":"2024-09-02T16:53:24.132361Z","shell.execute_reply":"2024-09-02T16:53:24.366458Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9167 - loss: 0.2730\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[0.4020724296569824, 0.8803418874740601]"},"metadata":{}}]}]}